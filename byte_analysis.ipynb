{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0900ecd3",
   "metadata": {},
   "source": [
    "# Byte Analysis and Huffman Compression Testing\n",
    "\n",
    "This notebook demonstrates how to read binary data from different file formats (.txt, .png, .wav) and test the Huffman compression algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7fe704",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0fbefa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "# Add the current directory to the path to import project modules\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "\n",
    "from core.file_utils import read_binary_file, display_all_bytes\n",
    "from core.huffman import huffman_encode, huffman_decode\n",
    "from utils.bit_utils import bits_to_bytes\n",
    "\n",
    "# Additional imports for handling different file types\n",
    "import wave  # For WAV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e78932",
   "metadata": {},
   "source": [
    "## 1. Reading Text Files\n",
    "\n",
    "Let's start by reading a text file in binary mode to examine its bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7856af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bytes in text file: 13\n",
      "\n",
      "First 50 bytes as integers:\n",
      "[104, 101, 108, 108, 111, 32, 104, 117, 102, 102, 109, 97, 110]\n",
      "\n",
      "First 50 bytes as ASCII:\n",
      "hello huffman\n"
     ]
    }
   ],
   "source": [
    "# Read the example text file in binary mode\n",
    "text_path = os.path.join('examples', 'input_text.txt')\n",
    "\n",
    "try:\n",
    "    text_bytes = read_binary_file(text_path)\n",
    "    print(f\"Number of bytes in text file: {len(text_bytes)}\")\n",
    "    print(\"\\nFirst 50 bytes as integers:\")\n",
    "    print(list(text_bytes[:50]))\n",
    "    print(\"\\nFirst 50 bytes as ASCII:\")\n",
    "    print(text_bytes[:50].decode('ascii'))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Text file not found at {text_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5d71c3",
   "metadata": {},
   "source": [
    "## 2. Reading PNG Files\n",
    "\n",
    "Now let's examine a PNG file's binary data, including its header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2dcbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple PNG file if it doesn't exist\n",
    "png_path = os.path.join('examples', 'test.png')\n",
    "\n",
    "if not os.path.exists(png_path):\n",
    "    # Create a small colored image\n",
    "    img = Image.new('RGB', (100, 100), color='red')\n",
    "    img.save(png_path)\n",
    "    print(f\"Created test PNG file at {png_path}\")\n",
    "\n",
    "# Read the PNG file in binary mode\n",
    "png_bytes = read_binary_file(png_path)\n",
    "\n",
    "# Examine the PNG header (first 8 bytes)\n",
    "png_header = png_bytes[:8]\n",
    "print(\"PNG Header (8 bytes):\")\n",
    "print(f\"As integers: {list(png_header)}\")\n",
    "print(f\"As hex: {png_header.hex()}\")\n",
    "\n",
    "# Expected PNG header: 89 50 4E 47 0D 0A 1A 0A\n",
    "print(\"\\nVerifying PNG signature...\")\n",
    "is_png = png_header.startswith(b'\\x89PNG\\r\\n\\x1a\\n')\n",
    "print(f\"Is valid PNG: {is_png}\")\n",
    "\n",
    "print(f\"\\nTotal file size: {len(png_bytes)} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f52be9",
   "metadata": {},
   "source": [
    "## 3. Reading WAV Files\n",
    "\n",
    "Let's examine a WAV file's binary data, focusing on its 44-byte header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1386656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze WAV header\n",
    "def analyze_wav_header(wav_path):\n",
    "    with wave.open(wav_path, 'rb') as wav_file:\n",
    "        print(f\"Number of channels: {wav_file.getnchannels()}\")\n",
    "        print(f\"Sample width: {wav_file.getsampwidth()} bytes\")\n",
    "        print(f\"Frame rate: {wav_file.getframerate()} Hz\")\n",
    "        print(f\"Number of frames: {wav_file.getnframes()}\")\n",
    "        print(f\"Compression type: {wav_file.getcomptype()}\")\n",
    "\n",
    "# Read a WAV file if it exists\n",
    "wav_path = os.path.join('examples', 'test.wav')\n",
    "\n",
    "try:\n",
    "    # Read the WAV file in binary mode\n",
    "    wav_bytes = read_binary_file(wav_path)\n",
    "    \n",
    "    # Examine the WAV header (first 44 bytes)\n",
    "    wav_header = wav_bytes[:44]\n",
    "    print(\"WAV Header (44 bytes):\")\n",
    "    print(f\"As integers: {list(wav_header)}\")\n",
    "    print(f\"As hex: {wav_header.hex()}\")\n",
    "    \n",
    "    print(\"\\nWAV File Analysis:\")\n",
    "    analyze_wav_header(wav_path)\n",
    "    \n",
    "    print(f\"\\nTotal file size: {len(wav_bytes)} bytes\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"WAV file not found at {wav_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2712e7e0",
   "metadata": {},
   "source": [
    "## 4. Testing Huffman Compression\n",
    "\n",
    "Let's test our Huffman compression algorithm on a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "180c1588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text length: 13 characters\n",
      "Original size: 13 bytes\n",
      "Counter({'h': 2, 'l': 2, 'f': 2, 'e': 1, 'o': 1, ' ': 1, 'u': 1, 'm': 1, 'a': 1, 'n': 1})\n",
      "[<core.huffman.HuffmanNode object at 0x7f518e5dfee0>, <core.huffman.HuffmanNode object at 0x7f518e5dfc40>, <core.huffman.HuffmanNode object at 0x7f518e0f86e0>, <core.huffman.HuffmanNode object at 0x7f518e0f8280>, <core.huffman.HuffmanNode object at 0x7f518e0f81a0>, <core.huffman.HuffmanNode object at 0x7f518e0f82f0>, <core.huffman.HuffmanNode object at 0x7f518e0f8130>, <core.huffman.HuffmanNode object at 0x7f518e0f84b0>, <core.huffman.HuffmanNode object at 0x7f518e0f8360>, <core.huffman.HuffmanNode object at 0x7f518e0f83d0>]\n",
      "\n",
      "Number of unique characters: 10\n",
      "Huffman codes:\n",
      "' ': 1110\n",
      "'a': 1011\n",
      "'e': 1111\n",
      "'f': 011\n",
      "'h': 00\n",
      "'l': 100\n",
      "'m': 010\n",
      "'n': 1101\n",
      "'o': 1010\n",
      "'u': 1100\n",
      "dict_values(['00', '010', '011', '100', '1010', '1011', '1100', '1101', '1110', '1111'])\n",
      "\n",
      "Compressed size: 6 bytes\n",
      "Compression ratio: 2.17x\n",
      "\n",
      "Decompression test:\n",
      "Decompressed length: 13 characters\n",
      "Decompression successful: True\n"
     ]
    }
   ],
   "source": [
    "# Read the text file content\n",
    "try:\n",
    "    with open(text_path, 'r', encoding='utf-8') as f:\n",
    "        text_content = f.read()\n",
    "    \n",
    "    print(f\"Original text length: {len(text_content)} characters\")\n",
    "    print(f\"Original size: {len(text_content.encode('utf-8'))} bytes\")\n",
    "    \n",
    "    # Compress using Huffman coding\n",
    "    encoded_data, codes = huffman_encode(text_content)\n",
    "    print(f\"\\nNumber of unique characters: {len(codes)}\")\n",
    "    print(\"Huffman codes:\")\n",
    "    for char, code in sorted(codes.items()):\n",
    "        if char.isprintable():\n",
    "            print(f\"'{char}': {code}\")\n",
    "        else:\n",
    "            print(f\"byte {ord(char)}: {code}\")\n",
    "    print(codes.values())\n",
    "    \n",
    "    # Convert encoded data to bytes for storage\n",
    "    encoded_bytes = bits_to_bytes(encoded_data)\n",
    "    print(f\"\\nCompressed size: {len(encoded_bytes)} bytes\")\n",
    "    \n",
    "    # Calculate compression ratio\n",
    "    compression_ratio = len(text_content.encode('utf-8')) / len(encoded_bytes)\n",
    "    print(f\"Compression ratio: {compression_ratio:.2f}x\")\n",
    "    \n",
    "    # Test decompression\n",
    "    decoded_text = huffman_decode(encoded_data, codes)\n",
    "    print(\"\\nDecompression test:\")\n",
    "    print(f\"Decompressed length: {len(decoded_text)} characters\")\n",
    "    print(f\"Decompression successful: {decoded_text == text_content}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Text file not found at {text_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefcd1e1",
   "metadata": {},
   "source": [
    "## 5. Detailed Byte Value Analysis\n",
    "\n",
    "Let's analyze and display all byte values in different formats for each file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2a678b",
   "metadata": {},
   "source": [
    "### Text File Byte Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566adf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\ttext_bytes = read_binary_file(text_path)\n",
    "\tdisplay_all_bytes(text_bytes, \"Text File\")\n",
    "except FileNotFoundError:\n",
    "  print(f\"Text file not found at {text_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06001237",
   "metadata": {},
   "source": [
    "### PNG File Byte Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    png_bytes = read_binary_file(png_path)\n",
    "    display_all_bytes(png_bytes, \"PNG File\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"PNG file not found at {png_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e002fba",
   "metadata": {},
   "source": [
    "### Encoded Data Byte Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f531177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'encoded_bytes' in locals():\n",
    "    display_all_bytes(encoded_bytes, \"Huffman Encoded Data\")\n",
    "else:\n",
    "    print(\"No encoded data available. Run the Huffman compression cells first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56c3fd7",
   "metadata": {},
   "source": [
    "### SARDINAS PATTERSON TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d64a409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniquely decodable: no new suffixes generated (algorithm stabilized).\n",
      "\n",
      "Codewords: ['00', '010', '011', '100', '1010', '1011', '1100', '1101', '1110', '1111']\n",
      "S1 (0): []\n",
      "S2 (0): []\n",
      "\n",
      "Result: Uniquely decodable\n"
     ]
    }
   ],
   "source": [
    "# Sardinas-Patterson test for unique decodability\n",
    "# Uses existing `codes` dict if available; otherwise falls back to the provided list.\n",
    "\n",
    "def sardinas_patterson(codewords, max_iters=1000):\n",
    "\tC = set(codewords)\n",
    "\t# S1: all non-empty suffixes y[len(x):] where y startswith x (x != y)\n",
    "\tdef suffixes_from(A, B):\n",
    "\t\tout = set()\n",
    "\t\tfor a in A:\n",
    "\t\t\tfor b in B:\n",
    "\t\t\t\tif b.startswith(a):\n",
    "\t\t\t\t\tsuf = b[len(a):]\n",
    "\t\t\t\t\tif suf:\n",
    "\t\t\t\t\t\tout.add(suf)\n",
    "\t\treturn out\n",
    "\n",
    "\tS = []\n",
    "\tS1 = suffixes_from(C, C)\n",
    "\tS.append(S1)\n",
    "\tseen = set(S1)\n",
    "\n",
    "\tif '' in S1:\n",
    "\t\tprint(\"Not uniquely decodable: empty suffix appears in S1\")\n",
    "\t\treturn False, S\n",
    "\n",
    "\tfor i in range(1, max_iters):\n",
    "\t\tprev = S[-1]\n",
    "\t\t# Si+1 = (suffixes from C against Si) U (suffixes from Si against C)\n",
    "\t\tnext_set = suffixes_from(C, prev) | suffixes_from(prev, C)\n",
    "\n",
    "\t\t# If empty string produced -> not UD\n",
    "\t\tif '' in next_set:\n",
    "\t\t\tS.append(next_set)\n",
    "\t\t\tprint(f\"Not uniquely decodable: empty suffix appears in S{i+1}\")\n",
    "\t\t\treturn False, S\n",
    "\n",
    "\t\t# If no new elements -> UD\n",
    "\t\tnew_elements = next_set - seen\n",
    "\t\tif not new_elements:\n",
    "\t\t\tS.append(next_set)\n",
    "\t\t\tprint(\"Uniquely decodable: no new suffixes generated (algorithm stabilized).\")\n",
    "\t\t\treturn True, S\n",
    "\n",
    "\t\tS.append(next_set)\n",
    "\t\tseen |= new_elements\n",
    "\n",
    "\t# Reached iteration limit without conclusion\n",
    "\tprint(\"Inconclusive: reached iteration limit\")\n",
    "\treturn None, S\n",
    "\n",
    "\n",
    "code_list = list(codes.values())\n",
    "is_ud, S_sets = sardinas_patterson(code_list)\n",
    "\n",
    "# Print results concisely\n",
    "print(\"\\nCodewords:\", code_list)\n",
    "for idx, s in enumerate(S_sets, start=1):\n",
    "\tprint(f\"S{idx} ({len(s)}):\", sorted(s))\n",
    "print(\"\\nResult:\", \"Uniquely decodable\" if is_ud is True else (\"Not uniquely decodable\" if is_ud is False else \"Inconclusive\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
